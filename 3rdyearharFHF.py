# -*- coding: utf-8 -*-
"""3rdYearHAR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PFTmKTMhj1lRhzKGSNkppmx8VNuL1LoO

# Imports, Data Handling
"""

import numpy as np
import pandas as pd
import os
import scipy as sp
from joblib import Parallel, delayed
import random
import statsmodels.api as sm
import sys
import copy
import numpy.matlib
import math
import matplotlib.pyplot as plt


#Load Data, uncomment when you need to load a dataset. This chunk is for the realized volatility dataset
temp=pd.read_csv('returns.csv')
data=temp.to_numpy()
data=np.sqrt(data)
"""# Models"""



#HAR Stuff
def HARmse(rvs,data,size,lags,target,skipper):
    window=size
    test=rvs.shape[0]-size
    if len(data.shape)<2:
        data=np.reshape(data,(data.shape[0],1))
    preds=np.empty(shape=(test-target,1))
    testing=np.empty(shape=(test-target,1))
    dataEnd=np.roll(np.log(np.array(rvs)),-1*target)
    dataEnd[-1*target]=np.nan
    dataExg=np.empty(shape=(rvs.shape[0],len(lags)))
    for j in range(len(lags)):
        temp=np.zeros(shape=(data.shape[0]))
        if j>0:
            for k in range(lags[j]-lags[j-1]):
                temp=temp+np.roll(np.log(np.array(data[:,0])),(lags[j]-k+1))
            temp=temp/(lags[j]-lags[j-1])
        else:
            for k in range(lags[j]-0):
                temp=temp+np.roll(np.log(np.array(data[:,0])),(lags[j]-k+1))
            temp=temp/(lags[j]-0)
        temp[0:lags[j]]=np.nan
        dataExg[:,j]=temp[range(0,data.shape[0],skipper)] #select only valid choices
    dataExg = sm.add_constant(dataExg) #dataset created
    for j in range(test-target):
        try: #Figure out how to do this better?
            model=sm.OLS(dataEnd[j:window+j], dataExg[j:window+j,:], missing='drop',hasconst=True)
            modelResults=model.fit()
            preds[j,0]=modelResults.predict(dataExg[window+j,:])[0]
            testing[j,0]=dataEnd[window+j]
        except ValueError:  #raised if `y` is empty.
            preds[j,0]=np.nan
            testing[j,0]=dataEnd[window+j]
    return MSE(testing, preds)

def TreeModelingF(rvs,data,window,maxLags,target,depth,skipper):
    valid=list()
    lags=np.empty(depth+1,dtype=int)
    for k in range(depth):
        lags[k]=k+1 #initialized, cannot start at 0
    lags[-1]=maxLags
    valid.append(copy.deepcopy(lags))
    while depth>0:
        counter=0
        for k in range(depth):
            if lags[k]==maxLags-(depth-k):
                counter=counter+1
        if counter==depth:
            break
        lags[-1*(counter)-2]=lags[-1*(counter)-2]+1
        for k in range(counter,0,-1):
              lags[-1*k-1]=lags[-1*(k+1)-1]+1
        valid.append(copy.deepcopy(lags))
    results=Parallel(n_jobs=-1,return_as='list')(delayed(HARmse) (rvs,data,window,valid[i],target,skipper) for i in range(len(valid)))
    minindex=0
    bestmse=results[minindex]
    bestlags=valid[minindex]
    for i in range(len(results)):
        if results[i]<results[minindex]:
            minindex=i
            bestmse=results[minindex]
            bestlags=valid[minindex]
    return bestmse, list(bestlags)

#DM stuff
def HARgen(rvs,data,size,lags,target,skipper):
    window=size
    test=rvs.shape[0]-size
    if len(data.shape)<2:
        data=np.reshape(data,(data.shape[0],1))
    preds=np.empty(shape=(test-target,1))
    testing=np.empty(shape=(test-target,1))
    dataEnd=np.roll(np.log(np.array(rvs)),-1*target)
    dataEnd[-1*target]=np.nan
    dataExg=np.empty(shape=(rvs.shape[0],len(lags)))
    for j in range(len(lags)):
        temp=np.zeros(shape=(data.shape[0]))
        if j>0:
            for k in range(lags[j]-lags[j-1]):
                temp=temp+np.roll(np.log(np.array(data[:,0])),(lags[j]-k+1))
            temp=temp/(lags[j]-lags[j-1])
        else:
            for k in range(lags[j]-0):
                temp=temp+np.roll(np.log(np.array(data[:,0])),(lags[j]-k+1))
            temp=temp/(lags[j]-0)
        temp[0:lags[j]]=np.nan
        dataExg[:,j]=temp[range(0,data.shape[0],skipper)] #select only valid choices
    dataExg = sm.add_constant(dataExg) #dataset created
    for j in range(test-target):
        try: #Figure out how to do this better?
            model=sm.OLS(dataEnd[j:window+j], dataExg[j:window+j,:], missing='drop',hasconst=True)
            modelResults=model.fit()
            preds[j,0]=modelResults.predict(dataExg[window+j,:])[0]
            testing[j,0]=dataEnd[window+j]
        except ValueError:  #raised if `y` is empty.
            preds[j,0]=np.nan
            testing[j,0]=dataEnd[window+j]
    return testing, preds

def lossgen(actual, p1, p2):
    # Initialise lists
    e1_lst = np.empty(shape=actual.shape)
    e2_lst = np.empty(shape=actual.shape)
    d_lst  = np.empty(shape=actual.shape)
    # construct d according to crit
    e1=np.square(actual - p1)
    e2=np.square(actual - p2)
    d_lst=e1-e2
    return d_lst

def dm_test(d_lst,h=1):
    # Mean of d
    mean_d = np.nanmean(d_lst)
    T = float(d_lst.size - np.isnan(d_lst).sum())
    # Find autocovariance and construct DM test statistics
    def autocovariance(Xi, N, k, Xs):
        autoCov = 0
        T = 0
        for i in np.arange(0, N-k):
              if np.isnan((Xi[i+k]-Xs)*(Xi[i]-Xs)):
                  continue
              else:
                  autoCov += (Xi[i+k]-Xs)*(Xi[i]-Xs)
                  T=T+1
        return (1/(T))*autoCov
    gamma = []
    for lag in range(0,h):
        gamma.append(autocovariance(d_lst,len(d_lst),lag,mean_d)) # 0, 1, 2
    V_d=0
    if gamma[0]==np.nan:
        V_d = 2*np.nansum(gamma[1:])/T
    else:
        V_d = (gamma[0]+ 2*np.nansum(gamma[1:]))/T
    DM_stat=(np.abs(V_d)**(-0.5))*mean_d
    harvey_adj=((T+1-2*h+h*(h-1)/T)/T)**(0.5)
    DM_stat = harvey_adj*DM_stat
    return  DM_stat


"""# Utility Functions"""

#utility functions

def MSE(x,y):
    return np.sqrt(np.nanmean(np.square(x - y)))

"""# Configs

"""

MaxDepth=6 #Manually grab further depths if needed
window=500
targets=(1,5,22,44,66)
Finals=np.empty(shape=(len(targets),4))
results=np.empty(shape=(len(targets),MaxDepth+3))
lagpicks=np.empty(shape=(len(targets),MaxDepth+1),dtype=object)
times=["09:30","09:35","09:40","09:45","09:50","09:55"]
for i in range(10,16):
    for j in range(0,60,5):
        if j<10:
            times.append(str(i)+":0"+str(j))
        else:
            times.append(str(i)+":"+str(j))
times.append("16:00")
MaxLags=22*len(times)
data=data[~np.any(data==0,axis=1)]
rvs=data[:,-1]
data=data[:,:-1]
data=np.reshape(data, (data.shape[0]*data.shape[1],1))
for j in range(len(targets)):
    for k in range(MaxDepth+1):
        results[j,k],lagpicks[j,k]=TreeModelingF(rvs,data,window,MaxLags,targets[j],k,len(times))
    results[j,MaxDepth+1]=HARmse(rvs,rvs,window,(1,5,22),targets[j],1)
    minindex=0
    for k in range(MaxDepth+1):
        if results[j,k]<results[j,minindex]:
            minindex=k
    actual,preds1=HARgen(rvs,data,window,lagpicks[j,minindex],targets[j],len(times))
    actual,preds2=HARgen(rvs,rvs,window,(1,5,22),targets[j],1)
    losses=lossgen(actual,preds2,preds1)
    results[j,MaxDepth+2]=dm_test(losses,h=1)[0]
    Finals[j,0]=results[j,minindex]/results[j,MaxDepth+1]
    Finals[j,2]=results[j,MaxDepth+2]
s1="RHF/lagpicks.txt"
s2="RHF/results.txt"
s3="RHF/format.txt"
np.savetxt(s1,lagpicks,fmt='%s')
np.savetxt(s2,results)
np.savetxt(s3,results,fmt="%.4f",delimiter=" & " )
#DAILY stuff here.
resultsd=np.empty(shape=(len(targets),MaxDepth+3))
lagpicksd=np.empty(shape=(len(targets),MaxDepth+1),dtype=object)
MaxDepth=6 #reset for runtime
MaxLags=22
for j in range(len(targets)):
    for k in range(MaxDepth+1):
        resultsd[j,k],lagpicksd[j,k]=TreeModelingF(rvs,rvs,window,MaxLags,targets[j],k,1)
    resultsd[j,MaxDepth+1]=HARmse(rvs,rvs,window,(1,5,22),targets[j],1)
    minindexd=0
    minindex=0
    for k in range(MaxDepth+1):
        if resultsd[j,k]<resultsd[j,minindexd]:
            minindexd=k
        if results[j,k]<results[j,minindex]:
            minindex=k
    actual,preds2=HARgen(rvs,rvs,window,lagpicksd[j,minindexd],targets[j],1)
    actual,preds1=HARgen(rvs,data,window,lagpicks[j,minindex],targets[j],len(times))
    losses=lossgen(actual,preds2,preds1)
    resultsd[j,MaxDepth+2]=dm_test(losses,h=1)[0]
    Finals[j,1]=resultsd[j,minindexd]/resultsd[j,MaxDepth+1]
    Finals[j,3]=resultsd[j,MaxDepth+2]
s1="RHF/dlagpicks.txt"
s2="RHF/dresults.txt"
s3="RHF/dformat.txt"
s4="RHF/Finals.txt"
np.savetxt(s1,lagpicksd,fmt='%s')
np.savetxt(s2,resultsd)
np.savetxt(s3,resultsd,fmt="%.4f",delimiter=" & " )
np.savetxt(s4,Finals,fmt="%.4f", delimiter= " & ")
